measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_filter <- po("filter", filter = flt("auc"), filter.nfeat = 3, id = "selection")
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
# 1. Creazione dei Learner (usando i tuoi grafi)
# Assicurati che task, po_us e po_filter siano definiti come prima
list_learners = list(
GraphLearner$new(po_us %>>% po_filter %>>% lrn("classif.lda", predict_type = "prob"), id = "LDA"),
GraphLearner$new(po_us %>>% po_filter %>>% lrn("classif.qda", predict_type = "prob"), id = "QDA"),
)
# 1. Creazione dei Learner (usando i tuoi grafi)
# Assicurati che task, po_us e po_filter siano definiti come prima
list_learners = list(
GraphLearner$new(po_us %>>% po_filter %>>% lrn("classif.lda", predict_type = "prob"), id = "LDA"),
GraphLearner$new(po_us %>>% po_filter %>>% lrn("classif.qda", predict_type = "prob"), id = "QDA")
)
# 2. Creazione del Design e Benchmark
design = benchmark_grid(
tasks = task,
learners = list_learners,
resamplings = rsmp("cv", folds = 5)
)
# Esecuzione (store_models = TRUE qui è fondamentale)
bmr = benchmark(design, store_models = TRUE)
# 3. Funzione di estrazione universale per Benchmark
estrai_da_benchmark = function(bmr_obj) {
# Estraiamo i risultati riga per riga (una per ogni modello)
for (i in 1:nrow(bmr_obj$data)) {
riferimento = bmr_obj$data[i, ]
nome_mod = riferimento$learner_id
res_result = riferimento$resample_result[[1]]
cat("\n========================================")
cat("\n MODELLO:", nome_mod)
cat("\n========================================\n")
# Estraiamo le feature da ogni fold
fold_data = lapply(seq_along(res_result$models), function(j) {
m = res_result$models[[j]]
# Navigazione: KNN (AutoTuner) vs LDA/QDA
# Se l'ID è KNN cerchiamo in learner$model, altrimenti in model
target = if (grepl("knn", nome_mod, ignore.case = TRUE)) m$learner$model else m$model
# "selection" è l'id che hai dato al po_filter
feats = target$selection$state$features
scores = target$selection$state$score[feats]
data.frame(Fold = j, Feature = feats, Score = round(as.numeric(scores) + 0.5, 3))
})
print(do.call(rbind, fold_data))
}
}
# 4. ESECUZIONE
estrai_da_benchmark(bmr)
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc$calculate(task)
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$score)
colnames(df_scores) = "Score_AUC_Raw"
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc$calculate(task)
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$score)
task
filter_auc
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc
filter_auc$calculate(task)
filter_auc
filter_auc$scores
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$scores)
colnames(df_scores) = "Score_AUC_Raw"
df_scores$Feature = rownames(df_scores)
df_scores
# Calcoliamo l'AUC Reale (Punteggio + 0.5)
df_scores$AUC_Real = round(df_scores$Score_AUC_Raw + 0.5, 3)
df_scores = df_scores[order(-df_scores$AUC_Real), ]
df_scores
# Vediamo le migliori 10
print(head(df_scores, 10))
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features = head(df_scores$Feature, 5)
library(pROC)
dati_test <- task$data()
roc_test <- roc(dati_test$class, dati_test$VV1934)
dati_test
library(pROC)
dati_test <- task$data()
roc_test <- roc(dati_test$class, dati_test$V1934)
cat("L'AUC reale per la feature è:", roc_test$auc)
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc$calculate(task)
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$scores)
colnames(df_scores) = "Score_AUC_Raw"
# Calcoliamo l'AUC Reale (Punteggio + 0.5)
df_scores$AUC_Real = round(df_scores$Score_AUC_Raw + 0.5, 3)
df_scores
# Vediamo le migliori 10
print(head(df_scores, 10))
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- head(df_scores$Feature, 5)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
knn <- lrn("classif.kknn", predict_type = "prob")
graph_knn <- po_us %>>% knn
learner_knn <- GraphLearner$new(graph_knn)
search_space <- ps(
classif.kknn.k = p_int(3, 10)
)
at_knn <- AutoTuner$new(
learner = learner_knn,
resampling = rsmp("cv", folds = 5),
measure = msr("classif.auc"),
search_space = search_space,
tuner = tnr("random_search"),
terminator = trm("evals", n_evals = 30)
)
resampling_outer <- rsmp("cv", folds = 5)
rr_knn <- mlr3::resample(task, at_knn, resampling_outer, store_models = TRUE)
rr_knn$aggregate(measures)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
rr_knn$aggregate(measures)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
# LDA
rr_lda$aggregate(measures)
# QDA
rr_qda$aggregate(measures)
graph_qda <- po_us %>>% qda
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc$calculate(task)
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$scores)
colnames(df_scores) = "Score_AUC_Raw"
# Calcoliamo l'AUC Reale (Punteggio + 0.5)
df_scores$AUC_Real = round(df_scores$Score_AUC_Raw + 0.5, 3)
# Vediamo le migliori 10
print(head(df_scores, 10))
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- head(df_scores$Feature, 3)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
resampling_outer <- rsmp("cv", folds = 5)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc$calculate(task)
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$scores)
colnames(df_scores) = "Score_AUC_Raw"
# Calcoliamo l'AUC Reale (Punteggio + 0.5)
df_scores$AUC_Real = round(df_scores$Score_AUC_Raw + 0.5, 3)
# Vediamo le migliori 10
print(head(df_scores, 10))
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- head(df_scores$Feature, 3)
data.cluster <- data.cluster |> dplyr::select(top_features, class)
top_features
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- head(df_scores$Feature, 3)
top_features
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc$calculate(task)
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$scores)
colnames(df_scores) = "Score_AUC_Raw"
# Calcoliamo l'AUC Reale (Punteggio + 0.5)
df_scores$AUC_Real = round(df_scores$Score_AUC_Raw + 0.5, 3)
# Vediamo le migliori 10
print(head(df_scores, 10))
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- head(df_scores$Feature, 3)
top_features
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[1:5,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
resampling_outer <- rsmp("cv", folds = 5)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
# LDA
rr_lda$aggregate(measures)
# QDA
rr_qda$aggregate(measures)
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[1:3,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
resampling_outer <- rsmp("cv", folds = 5)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
# LDA
rr_lda$aggregate(measures)
# QDA
rr_qda$aggregate(measures)
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[1,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
resampling_outer <- rsmp("cv", folds = 5)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
# LDA
rr_lda$aggregate(measures)
# QDA
rr_qda$aggregate(measures)
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[2,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[1:2,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
data.analysis <- readRDS("data/intermediate/data analysis.rds")
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", colnames(data.analysis), value = TRUE))
colnames(data.cluster) <- paste0("V", colnames(data.cluster))
data.cluster <- bind_cols(data.cluster, class = data.analysis$class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
# Usiamo il filtro AUC direttamente sul task
filter_auc = flt("auc")
filter_auc$calculate(task)
# Estraiamo i punteggi e creiamo una tabella ordinata
df_scores = as.data.frame(filter_auc$scores)
colnames(df_scores) = "Score_AUC_Raw"
# Calcoliamo l'AUC Reale (Punteggio + 0.5)
df_scores$AUC_Real = round(df_scores$Score_AUC_Raw + 0.5, 3)
# Vediamo le migliori 10
print(head(df_scores, 10))
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[1:2,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
resampling_outer <- rsmp("cv", folds = 5)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
# LDA
rr_lda$aggregate(measures)
# QDA
rr_qda$aggregate(measures)
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[1,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
resampling_outer <- rsmp("cv", folds = 5)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
# LDA
rr_lda$aggregate(measures)
# QDA
rr_qda$aggregate(measures)
# Salviamo i nomi delle migliori 5 feature per i modelli successivi
top_features <- rownames(df_scores[1,])
data.cluster <- data.cluster |> dplyr::select(top_features, class)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
task$col_roles$stratum <- "class"
measures <- list(
msr("classif.acc"),
msr("classif.auc"),
msr("classif.ce"),
msr("classif.sensitivity"),
msr("classif.specificity")
)
po_us <- po("classbalancing", adjust = "minor", reference = "major", id = "balance")
resampling_outer <- rsmp("cv", folds = 5)
lda <- lrn("classif.lda", predict_type = "prob")
qda <- lrn("classif.qda", predict_type = "prob")
graph_lda <- po_us %>>% lda
graph_qda <- po_us %>>% qda
rr_lda <- mlr3::resample(task, GraphLearner$new(graph_lda), resampling_outer, store_models = TRUE)
rr_qda <- mlr3::resample(task, GraphLearner$new(graph_qda), resampling_outer, store_models = TRUE)
# LDA
rr_lda$aggregate(measures)
# QDA
rr_qda$aggregate(measures)
source("settings.R")
data.analysis <- readRDS("data/intermediate/data analysis.rds")
cor.data <- data.analysis |> dplyr::select(!c(sample, class))
corr_Kvalue <- cor(cor.data)["K value",]
top.cor <- sort(abs(corr_Kvalue), decreasing = TRUE)
top.cor <- head(top.cor, 10)
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", names(top.cor), value = TRUE), class)
names(data.cluster)
data.analysis <- readRDS("data/intermediate/data analysis.rds")
cor.data <- data.analysis |> dplyr::select(!c(sample, class))
corr_Kvalue <- cor(cor.data)["K value",]
top.cor <- sort(abs(corr_Kvalue), decreasing = TRUE)
top.cor <- head(top.cor, 10)
data.cluster <- data.analysis |> dplyr::select(grep("^[[:digit:]]*$", names(top.cor), value = TRUE), class)
set.seed(123)
task <- TaskClassif$new(
id = "Classification original data",
backend = data.cluster,
target = "class",
positive = "fresco"
)
source("settings.R")
source("code/Functions.R")
